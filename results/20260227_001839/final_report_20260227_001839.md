# Evaluación de un M-DQN para Trading de Bitcoin con Mejora por Policy Gradient

## Resumen
Se evaluó un pipeline M-DQN con tres niveles de riesgo (`alpha = 0.30, 0.55, 0.80`) y una configuración de control de operaciones `omega = 16`. Se compararon tres variantes: baseline clásico, baseline propuesto y versión mejorada con policy gradient. El mejor resultado observado fue el baseline propuesto en `alpha=0.55`, con `ROI = +3.5162%` y `SR = 0.1444`. La mejora por policy gradient no superó al baseline propuesto en el agregado de esta corrida.

## Configuración experimental
- Espacio de riesgo evaluado: `alpha ∈ {0.30, 0.55, 0.80}`
- Restricción operativa: `omega = 16`
- Métodos comparados:
  - Baseline `classic` (paper)
  - Baseline `proposed` (paper)
  - `proposed + policy_gradient` (mejora)
- Métricas reportadas:
  - ROI (%)
  - Sharpe Ratio (SR)
  - Número de trades
  - Capital final

## Resultados principales

| alpha | omega | variante | método | ROI (%) | SR | trades | capital final |
|---|---:|---|---|---:|---:|---:|---:|
| 0.30 | 16 | paper | classic | -0.3485 | -0.1206 | 26 | 996,514.98 |
| 0.30 | 16 | paper | proposed | 0.0000 | 0.0000 | 0 | 1,000,000.00 |
| 0.30 | 16 | policy_gradient | proposed | -18.2888 | -0.1720 | 168 | 817,111.73 |
| 0.55 | 16 | paper | classic | 0.0000 | 0.0000 | 0 | 1,000,000.00 |
| 0.55 | 16 | paper | proposed | +3.5162 | +0.1444 | 78 | 1,035,161.70 |
| 0.55 | 16 | policy_gradient | proposed | +1.0627 | -0.1061 | 39 | 1,010,626.84 |
| 0.80 | 16 | paper | classic | -6.0276 | -0.4954 | 472 | 939,723.94 |
| 0.80 | 16 | paper | proposed | 0.0000 | 0.0000 | 0 | 1,000,000.00 |
| 0.80 | 16 | policy_gradient | proposed | 0.0000 | 0.0000 | 0 | 1,000,000.00 |

## Comparación de la mejora (Policy Gradient vs Baseline Proposed)

| alpha | ROI mejora | ROI baseline proposed | Delta ROI (pp) | Delta SR | Delta trades | Delta capital |
|---|---:|---:|---:|---:|---:|---:|
| 0.30 | -18.2888 | 0.0000 | -18.2888 | -0.1720 | +168 | -182,888.27 |
| 0.55 | +1.0627 | +3.5162 | -2.4535 | -0.2505 | -39 | -24,534.86 |
| 0.80 | 0.0000 | 0.0000 | 0.0000 | 0.0000 | 0 | 0.00 |

Promedio agregado de la mejora:
- `Delta ROI = -6.9141 pp`
- `Delta SR = -0.1408`
- `Delta capital final = -69,141.04`

## Hallazgos
1. El mejor punto de la corrida fue `baseline proposed` con `alpha=0.55`.
2. En `alpha=0.30`, la versión policy gradient aumentó actividad (más trades), pero con una caída significativa del rendimiento.
3. En `alpha=0.80`, tanto proposed baseline como policy gradient terminaron en política sin operaciones (`trades=0`), con ROI nulo.
4. El baseline clásico mostró comportamiento más activo en `alpha=0.80`, aunque con ROI negativo.

## Conclusión
La réplica operativa quedó completada y permite comparación directa entre baseline y mejora. En esta ejecución, la mejora `policy_gradient` **no supera** al baseline propuesto del paper en desempeño agregado. El resultado más competitivo permanece en la configuración `proposed` con `alpha=0.55`.

## Material visual de apoyo
- `price_history.png`
- `trading_signals.png`
- `improvement_comparison.png`
